{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ENSEMBLE_Face_Comparison.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9_Ie1hwsz2qd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dAKkrjH4GDKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8dd1ae8-d72d-4dae-ee4f-fc113b5ef60c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Project/Face Comparison/project.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')"
      ],
      "metadata": {
        "id": "R6f6ptzRteUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'READ ONE TEXT FILE'\n",
        "def get_feature(file_path):\n",
        "  with open(file_path, 'r') as f:\n",
        "    img_embedding = f.read()[2:-2].split(' ')\n",
        "    img_embedding = [float(each_num.replace('\\n', '')) for each_num in img_embedding if each_num!='']\n",
        "  return img_embedding\n",
        "\n",
        "sample_features = get_feature('/content/lfw/AJ_Cook/AJ_Cook_0001.txt')\n",
        "print('LEN FEATURE IS \"{}\" AND ONE SAMPLE IS --> {}.'.format(len(sample_features), sample_features))"
      ],
      "metadata": {
        "id": "uP0zMquVoJ92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Dense, Input, Lambda\n",
        "from keras.models import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from keras import backend as K\n",
        "import statistics\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "Ql4a5OHxzKJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_path = './lfw/'\n",
        "train_path = '/content/pairsDevTrain.txt'\n",
        "test_path = '/content/pairsDevTest.txt'\n",
        "\n",
        "\n",
        "def generate_image_pairs(images_path, file_path):\n",
        "  with open(file_path, 'r') as f:\n",
        "    pairs_train = f.readlines()\n",
        "    pairs_train = [pair.replace('\\n', '').split('\\t') for pair in pairs_train]\n",
        "    pairs_train_pos = pairs_train[1:int(pairs_train[0][0])+1]\n",
        "    pairs_train_neg = pairs_train[int(pairs_train[0][0])+1:]\n",
        "\n",
        "  pairs_train_pos_df = pd.DataFrame(pairs_train_pos, columns=['Folder', 'Image1', 'Image2'])\n",
        "  pairs_train_neg_df = pd.DataFrame(pairs_train_neg, columns=['Folder1', 'Image1', 'Folder2', 'Image2'])\n",
        "\n",
        "  X_POS = []\n",
        "  'SAME IMAGES PAIRS'\n",
        "  for index, each_pair_pos in pairs_train_pos_df.iterrows():\n",
        "    \n",
        "    image1_feature = get_feature(images_path+each_pair_pos['Folder']+'/'+each_pair_pos['Folder']+'_'+\n",
        "                                 f\"{int(each_pair_pos['Image1']):04}\"+'.txt')\n",
        "    image2_feature = get_feature(images_path+each_pair_pos['Folder']+'/'+each_pair_pos['Folder']+'_'+\n",
        "                                 f\"{int(each_pair_pos['Image2']):04}\"+'.txt')\n",
        "    X_POS.append([image1_feature, image2_feature, 1])\n",
        "\n",
        "  X_NEG = []\n",
        "  'DIFFERENT IMAGES PAIRS'\n",
        "  for index, each_pair_neg in pairs_train_neg_df.iterrows():\n",
        "    image1_feature = get_feature(images_path+each_pair_neg['Folder1']+'/'+each_pair_neg['Folder1']+\n",
        "                                 '_'+f\"{int(each_pair_neg['Image1']):04}\"+'.txt')\n",
        "    image2_feature = get_feature(images_path+each_pair_neg['Folder2']+'/'+each_pair_neg['Folder2']+\n",
        "                                 '_'+f\"{int(each_pair_neg['Image2']):04}\"+'.txt')\n",
        "    X_NEG.append([image1_feature, image2_feature, 0])\n",
        "\n",
        "\n",
        "  ALL_X = X_POS + X_NEG\n",
        "  random.shuffle(ALL_X)\n",
        "  images_pair1 = np.array([item[0] for item in ALL_X])\n",
        "  images_pair2 = np.array([item[1] for item in ALL_X])\n",
        "  labels_pair = np.array([item[2] for item in ALL_X])\n",
        "  return images_pair1, images_pair2, labels_pair\n",
        "  \n",
        "\n",
        "images_pair1_TRAIN, images_pair2_TRAIN, labels_pair_TRAIN = generate_image_pairs(images_path, train_path)\n",
        "images_pair1_TEST, images_pair2_TEST, labels_pair_TEST = generate_image_pairs(images_path, test_path)"
      ],
      "metadata": {
        "id": "C4AacInvHN0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(hidden, images_pair1, images_pair2, labels_pair):\n",
        "  MAX_LEN = 512\n",
        "  first_image_in = Input(shape=(MAX_LEN,))\n",
        "  second_image_in = Input(shape=(MAX_LEN,))\n",
        "  \n",
        "  dense = Dense(hidden, activation='relu')\n",
        "  first_sent_encoded = dense(first_image_in)\n",
        "  second_sent_encoded = dense(second_image_in)\n",
        "\n",
        "  l1_norm = lambda x: 1 - K.abs(x[0] - x[1])\n",
        "  merged = Lambda(function=l1_norm, output_shape=lambda x: x[0])([first_sent_encoded,\n",
        "                                                                  second_sent_encoded])\n",
        "  predictions = Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "  model = Model([first_image_in, second_image_in], predictions)\n",
        "\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics=[\"accuracy\"])\n",
        "  print(model.summary())\n",
        "\n",
        "  model.fit([images_pair1, images_pair2], labels_pair, validation_split=0.1, epochs = 20,shuffle=True, batch_size = 512)\n",
        "\n",
        "  model.save('./'+'Model'+str(hidden))\n"
      ],
      "metadata": {
        "id": "IHCM1ImneId_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(32, images_pair1_TRAIN, images_pair2_TRAIN, labels_pair_TRAIN)\n",
        "train_model(64, images_pair1_TRAIN, images_pair2_TRAIN, labels_pair_TRAIN)\n",
        "train_model(128, images_pair1_TRAIN, images_pair2_TRAIN, labels_pair_TRAIN)"
      ],
      "metadata": {
        "id": "LmorX_5pyTe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'TEST'\n",
        "\n",
        "# hidden_model128 = keras.models.load_model('/content/Model128')\n",
        "# hidden_model64 = keras.models.load_model('/content/Model64')\n",
        "# hidden_model32 = keras.models.load_model('/content/Model32')\n",
        "\n",
        "'ONE SAMPLE TEST'\n",
        "# index = 100\n",
        "# test_image1 = np.expand_dims(images_pair1_TEST[index], axis=0)\n",
        "# test_image2 = np.expand_dims(images_pair2_TEST[index], axis=0)\n",
        "\n",
        "\n",
        "# print(hidden_model128.predict([test_image1, test_image2]), labels_pair_TEST[index])\n",
        "# print(hidden_model64.predict([test_image1, test_image2]), labels_pair_TEST[index])\n",
        "# print(hidden_model32.predict([test_image1, test_image2]), labels_pair_TEST[index])\n",
        "\n",
        "'ALL DATA TEST TOGETHER'\n",
        "def get_predicts(model_path, images_pair1_TEST, images_pair2_TEST):\n",
        "  model = keras.models.load_model(model_path)\n",
        "  predict_labels = [round(each_predict[0]) for each_predict in model.predict([images_pair1_TEST, images_pair2_TEST])]\n",
        "  return predict_labels\n",
        "\n",
        "\n",
        "predict_labels_model128 = get_predicts('/content/Model128', images_pair1_TEST, images_pair2_TEST)\n",
        "predict_labels_model64 = get_predicts('/content/Model64', images_pair1_TEST, images_pair2_TEST)\n",
        "predict_labels_model32 = get_predicts('/content/Model32', images_pair1_TEST, images_pair2_TEST)\n"
      ],
      "metadata": {
        "id": "EX-vX3n3eIzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predicts_ensemble(model_paths, images_pair1_TEST, images_pair2_TEST):\n",
        "  if len(model_paths)!=3:\n",
        "    print('THREE MODELS NEEDED!')\n",
        "    return None\n",
        "  model1 = keras.models.load_model(model_paths[0])\n",
        "  model2 = keras.models.load_model(model_paths[1])\n",
        "  model3 = keras.models.load_model(model_paths[2])\n",
        "\n",
        "  predict_labels_1 = [round(each_predict[0]) for each_predict in model1.predict([images_pair1_TEST, images_pair2_TEST])]\n",
        "  predict_labels_2 = [round(each_predict[0]) for each_predict in model2.predict([images_pair1_TEST, images_pair2_TEST])]\n",
        "  predict_labels_3 = [round(each_predict[0]) for each_predict in model3.predict([images_pair1_TEST, images_pair2_TEST])]\n",
        "\n",
        "  ensemble_predicts = []\n",
        "  for i in range(len(predict_labels_1)):\n",
        "    ensemble_predicts.append(statistics.mode([predict_labels_1[i], predict_labels_2[i], predict_labels_3[i]]))\n",
        "  \n",
        "  return ensemble_predicts\n",
        "\n",
        "\n",
        "predict_labels_ensemble = get_predicts_ensemble(['/content/Model128', '/content/Model64', '/content/Model32'],\n",
        "                                                images_pair1_TEST, images_pair2_TEST)"
      ],
      "metadata": {
        "id": "YBRu0Enk4gqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('ACCURACY OF MODEL128 is \"{}\", ACCURACY OF MODEL64 is \"{}\" AND ACCURACY OF MODEL32 is \"{}\"'.format(\n",
        "    accuracy_score(labels_pair_TEST, predict_labels_model128),\n",
        "    accuracy_score(labels_pair_TEST, predict_labels_model64), \n",
        "    accuracy_score(labels_pair_TEST, predict_labels_model32)))\n",
        "print('ACCURACY OF ENSEMBLE is \"{}\".'.format(accuracy_score(labels_pair_TEST, predict_labels_ensemble)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKo2Jcxz2r5H",
        "outputId": "a923f225-70f5-4c59-dca9-44f4625975c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY OF MODEL128 is \"0.739\", ACCURACY OF MODEL64 is \"0.716\" AND ACCURACY OF MODEL32 is \"0.657\"\n",
            "ACCURACY OF ENSEMBLE is \"0.77\".\n"
          ]
        }
      ]
    }
  ]
}